# ماڈیول 4: وژن-لینگویج-ایکشن

## وائس ٹو ایکشن پائپ لائن: روبوٹکس میں زبان کا انضمام

روبوٹس، خاص طور پر ہیومینائڈز، کے لئے قدرتی زبان میں دیے گئے پیچیدہ احکامات کو سمجھنا اور ان پر عمل کرنا روبوٹکس کا ایک نیا میدان ہے۔ "وائس ٹو ایکشن" پائپ لائن انسانی ارادے، جو کہ تقریر کے ذریعے ظاہر ہوتا ہے، اور روبوٹک عملدرآمد کے درمیان پل کا کام کرتی ہے، لسانی ہدایات کو جسمانی اعمال کی ترتیب میں تبدیل کرتی ہے۔ یہ پائپ لائن عام طور پر کئی مراحل پر مشتمل ہوتی ہے: اسپیچ ٹو ٹیکسٹ، نیچرل لینگویج انڈرسٹینڈنگ (NLU) یا بڑے لینگویج ماڈل (LLM) پلاننگ، اور ایکشن ایکزیکیوشن۔

### مرحلہ 1: اسپیچ ٹو ٹیکسٹ (Whisper انٹیگریشن)

پہلا قدم بولے گئے احکامات کو درست طریقے سے متن میں تبدیل کرنا ہے۔ OpenAI کا Whisper ماڈل مضبوط اسپیچ ریکگنیشن کے لئے ایک جدید حل کے طور پر ابھرا ہے، جو مختلف زبانوں، لہجوں، اور شور والے ماحول کو سنبھالنے کی صلاحیت رکھتا ہے۔

-   **عمل:**
    1.  **آڈیو کیپچر:** روبوٹ کے مربوط مائیکروفون مسلسل محیطی آڈیو کو کیپچر کرتے ہیں یا خاص طور پر کسی وییک ورڈ کے لئے سنتے ہیں۔
    2.  **پری پروسیسنگ:** آڈیو سگنلز کو پری پروسیس کیا جاتا ہے (مثلاً، شور کی کمی، وائس ایکٹیویٹی ڈیٹیکشن) تاکہ ٹرانسکرپشن کی درستگی بہتر ہو سکے۔
    3.  **Whisper انفرنس:** پروسیس شدہ آڈیو کو Whisper ماڈل میں فیڈ کیا جاتا ہے، جو بولے گئے حکم کا ٹیکسٹ ٹرانسکرپٹ آؤٹ پٹ کرتا ہے۔ یہ روبوٹ کے ایج ڈیوائس (مثلاً، NVIDIA Jetson) پر چلایا جا سکتا ہے یا کمپیوٹیشنل وسائل اور لیٹنسی کی ضروریات کے مطابق کلاؤڈ سروس پر آف لوڈ کیا جا سکتا ہے۔
    4.  **ROS 2 انٹرفیس:** ٹرانسکرائب شدہ ٹیکسٹ کو عام طور پر ROS 2 ٹاپک (مثلاً، `/voice_commands/text`) پر `std_msgs/String` پیغام کے طور پر شائع کیا جاتا ہے، جو روبوٹک سسٹم کے دیگر حصوں کے لئے دستیاب ہوتا ہے۔

-   **Whisper کے فوائد:** اعلیٰ درستگی، کثیر لسانی حمایت، پس منظر کے شور کے خلاف مضبوطی، اور روبوٹکس سے متعلق تکنیکی اصطلاحات کو ٹرانسکرائب کرنے کی صلاحیت۔

### مرحلہ 2: LLM پلاننگ اور نیچرل لینگویج انڈرسٹینڈنگ (NLU)

ایک بار بولے گئے حکم کو متن میں ٹرانسکرائب کرنے کے بعد، اگلا اہم مرحلہ انسانی ارادے کو سمجھنا اور اسے روبوٹ کے قابل عمل منصوبے میں تبدیل کرنا ہے۔ بڑے لینگویج ماڈلز (LLMs) اس میں مہارت رکھتے ہیں، اپنی وسیع معلومات اور استدلال کی صلاحیتوں کا فائدہ اٹھاتے ہوئے۔

-   **LLM کا پلاننگ میں کردار:**
    1.  **سیمانٹک پارسنگ:** LLM قدرتی زبان کے حکم کے معنی کی تشریح کرتا ہے، کلیدی اداروں، اعمال، پابندیوں، اور اہداف کی شناخت کرتا ہے۔
    2.  **ٹاسک ڈیکمپوزیشن:** پیچیدہ، اعلیٰ سطحی احکامات (مثلاً، "میرے لئے کافی بناؤ") کو چھوٹے، قابل انتظام ذیلی کاموں میں تقسیم کیا جاتا ہے (مثلاً، "کافی مشین پر جاؤ"، "بینز پیسو"، "کافی بناؤ")۔
    3.  **ایکشن سیکوینس جنریشن:** ہر ذیلی کام کے لئے، LLM روبوٹ کے قابل عمل اعمال کی ترتیب پیدا کرتا ہے، جو مخصوص روبوٹ APIs، ROS 2 سروسز، یا ایکشن گولز کو کالز ہو سکتی ہیں۔
    4.  **کانٹیکسچوئل ریزننگ:** LLMs ڈائیلاگ ہسٹری کو برقرار رکھ سکتے ہیں اور ماحولیاتی سیاق و سباق (مثلاً، بصری ادراک، داخلی روبوٹ کی حالت) کو شامل کر سکتے ہیں تاکہ منصوبوں کو بہتر بنایا جا سکے، ابہام کو سنبھالا جا سکے، اور حتیٰ کہ وضاحت طلب سوالات پوچھ سکیں۔
    5.  **ایرر ریکوری:** اگر کوئی عمل ناکام ہو جاتا ہے، تو LLM دوبارہ منصوبہ بندی کر سکتا ہے یا متبادل حکمت عملی تجویز کر سکتا ہے۔

-   **روبوٹکس کے لئے پرومپٹ انجینئرنگ:** روبوٹ کنٹرول کے لئے LLMs کا مؤثر استعمال "پرومپٹ انجینئرنگ" کی محتاط ضرورت ہوتی ہے—LLM کے رویے کو درست اور محفوظ روبوٹ منصوبے پیدا کرنے کی طرف رہنمائی کرنے کے لئے ان پٹ پرومپٹس کی تشکیل۔
    -   **سسٹم پرومپٹس:** LLM کے کردار کو روبوٹ اسسٹنٹ کے طور پر متعین کریں، اس کی صلاحیتوں، دستیاب ٹولز (روبوٹ APIs/ROS انٹرفیس)، حفاظتی پابندیوں، اور آؤٹ پٹ فارمیٹ (مثلاً، اعمال کی JSON فہرست) کو واضح کریں۔
    -   **فیوشوٹ مثالیں:** کامیاب قدرتی زبان کے احکامات اور ان کے متعلقہ روبوٹ ایکشن سیکوینسز کی مثالیں فراہم کریں تاکہ LLM کو مطلوبہ رویے سکھائے جا سکیں۔
    -   **موجودہ حالت کی معلومات:** موجودہ سینسر ریڈنگز، روبوٹ کی جگہ، اور اشیاء کی حالتوں کو پرومپٹ میں شامل کریں تاکہ سیاق و سباق کے مطابق منصوبہ بندی کو فعال کیا جا سکے۔
    -   **ٹول-یوز/فنکشن کالنگ:** LLMs کو مخصوص روبوٹ فنکشنز کو "کال" کرنے کے لئے پرومپٹ کیا جا سکتا ہے (مثلاً، `move_to(location)`, `grasp_object(object_id)`)، ایک ذہین آرکیسٹریٹر کے طور پر کام کرتے ہوئے۔

### مرحلہ 3: ROS 2 ایکشن پائپ لائن برائے عملدرآمد

LLM کے ذریعہ پیدا کردہ ایکشن سیکوینسز کو پھر روبوٹ کے کنٹرول سسٹم کے ذریعہ عمل میں لایا جاتا ہے، جو عام طور پر ROS 2 ایکشن پائپ لائن کے ذریعے ترتیب دیا جاتا ہے۔ یہ فریم ورک طویل مدتی، مقصد پر مبنی کاموں کے لئے ڈیزائن کیا گیا ہے جو مسلسل فیڈ بیک کی ضرورت ہوتی ہے اور پیشگی روک تھام کی اجازت دیتا ہے۔

-   **اجزاء:**
    1.  **ایکشن کلائنٹ (LLM انٹرفیس):** ایک ROS 2 نوڈ LLM کے ساتھ انٹرفیس کرتا ہے۔ جب LLM ایک عمل پیدا کرتا ہے، تو ایکشن کلائنٹ مناسب ایکشن سرور کو `Action Goal` بھیجتا ہے۔
    2.  **ایکشن سرور (روبوٹ کنٹرولر):** ایک مخصوص نوڈ (مثلاً، نیویگیشن کنٹرولر، مینپولیشن کنٹرولر) جو گول کو وصول کرتا ہے، کام کو انجام دیتا ہے، اور اپنی پیشرفت پر `Feedback` بھیجتا ہے۔
    3.  **فیڈ بیک:** ایکشن سرور وقتاً فوقتاً فیڈ بیک پیغامات شائع کرتا ہے (مثلاً، "روبوٹ ہدف کی طرف بڑھ رہا ہے"، "گریپر بند ہو رہا ہے")، جسے ایکشن کلائنٹ مانیٹر کر سکتا ہے۔ یہ فیڈ بیک LLM کو حقیقی وقت کی نگرانی یا دوبارہ منصوبہ بندی کے لئے بھی فیڈ کیا جا سکتا ہے۔
    4.  **نتیجہ:** تکمیل پر، ایکشن سرور ایک حتمی `Result` (کامیابی/ناکامی، عملدرآمد کی تفصیلات) ایکشن کلائنٹ کو بھیجتا ہے۔

-   **مثال کا فلو:**
    1.  **وائس کمانڈ:** "روبوٹ، براہ کرم میز سے سرخ کپ لے آؤ۔"
    2.  **Whisper:** "روبوٹ، براہ کرم میز سے سرخ کپ لے آؤ" کو ٹرانسکرائب کرتا ہے۔
    3.  **LLM پلاننگ:**
        *   اسے تقسیم کرتا ہے: `navigate_to_table()`, `perceive_red_cup()`, `grasp_object(red_cup_id)`, `navigate_to_user()`, `release_object()`.
        *   ROS 2 ایکشن گولز کی ترتیب پیدا کرتا ہے۔
    4.  **ROS 2 عملدرآمد:**
        *   LLM انٹرفیس نیویگیشن ایکشن سرور کو `navigate_to_table` گول بھیجتا ہے۔
        *   روبوٹ حرکت کرتا ہے، نیویگیشن ایکشن سرور فیڈ بیک بھیجتا ہے۔
        *   `navigate_to_table` کی کامیابی پر، LLM انٹرفیس پرسیپشن ایکشن سرور کو `perceive_red_cup` گول بھیجتا ہے۔
        *   اور اسی طرح، اعمال کو جوڑتا ہے اور موافق رویے کے لئے فیڈ بیک کا استعمال کرتا ہے۔

یہ وژن-لینگویج-ایکشن (VLA) پیراڈائم، LLMs کو مرکزی علمی انجن کے طور پر استعمال کرتے ہوئے، پیچیدہ، انسانی مرکوز ماحول میں کام کرنے کے قابل ورسٹائل اور بدیہی ہیومینائڈ روبوٹس کی ترقی کے لئے اہم ہے۔